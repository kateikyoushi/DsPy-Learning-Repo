{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314cecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# !pip install dspy-ai litellm mlflow python-dotenv\n",
    "\n",
    "import dspy\n",
    "import mlflow\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9318d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/04 14:17:50 INFO mlflow.tracking.fluent: Experiment with name 'DSPy-Optimizer-Groq' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” MLflow tracing enabled with optimization tracking!\n",
      "ðŸ“Š Experiment: DSPy-Optimizer-Groq\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up MLflow experiment\n",
    "mlflow.set_experiment(\"DSPy-Optimizer-Groq\")\n",
    "\n",
    "# Enable comprehensive tracing for optimization\n",
    "mlflow.dspy.autolog(\n",
    "    log_evals=True,           # Log evaluation results\n",
    "    log_compiles=True,        # Log optimization process\n",
    "    log_traces_from_compile=True  # Trace during optimization\n",
    ")\n",
    "\n",
    "print(\"ðŸ” MLflow tracing enabled with optimization tracking!\")\n",
    "print(f\"ðŸ“Š Experiment: DSPy-Optimizer-Groq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d73891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Groq (Llama 3.3 70B Versatile) configured!\n",
      "Model: groq/llama-3.3-70b-versatile\n",
      "ðŸ“Š Free tier limits:\n",
      "   - Requests: 30/min, 1K/day\n",
      "   - Tokens: 12K/min, 100K/day\n",
      "\n",
      "Test: Capital of France = The capital of France is Paris.\n",
      "âœ… Groq connection verified!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## an...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    }
   ],
   "source": [
    "# Configure Groq with Llama 3.3 70B Versatile\n",
    "lm = dspy.LM(\n",
    "    'groq/llama-3.3-70b-versatile',\n",
    "    api_key=os.getenv('GROQ_API_KEY'),\n",
    "    max_tokens=1024,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Set as default LM\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "print(\"ðŸš€ Groq (Llama 3.3 70B Versatile) configured!\")\n",
    "print(f\"Model: {lm.model}\")\n",
    "print(f\"ðŸ“Š Free tier limits:\")\n",
    "print(f\"   - Requests: 30/min, 1K/day\")\n",
    "print(f\"   - Tokens: 12K/min, 100K/day\")\n",
    "\n",
    "# Quick test\n",
    "test = dspy.Predict(\"question -> answer\")\n",
    "result = test(question=\"What is the capital of France?\")\n",
    "print(f\"\\nTest: Capital of France = {result.answer}\")\n",
    "print(\"âœ… Groq connection verified!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
