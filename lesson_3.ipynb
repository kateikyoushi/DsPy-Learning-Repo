{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314cecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# !pip install dspy-ai litellm mlflow python-dotenv\n",
    "\n",
    "import dspy\n",
    "import mlflow\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9318d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/04 14:17:50 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/04 14:17:50 INFO mlflow.tracking.fluent: Experiment with name 'DSPy-Optimizer-Groq' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” MLflow tracing enabled with optimization tracking!\n",
      "ðŸ“Š Experiment: DSPy-Optimizer-Groq\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up MLflow experiment\n",
    "mlflow.set_experiment(\"DSPy-Optimizer-Groq\")\n",
    "\n",
    "# Enable comprehensive tracing for optimization\n",
    "mlflow.dspy.autolog(\n",
    "    log_evals=True,           # Log evaluation results\n",
    "    log_compiles=True,        # Log optimization process\n",
    "    log_traces_from_compile=True  # Trace during optimization\n",
    ")\n",
    "\n",
    "print(\"ðŸ” MLflow tracing enabled with optimization tracking!\")\n",
    "print(f\"ðŸ“Š Experiment: DSPy-Optimizer-Groq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d73891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Groq (Llama 3.3 70B Versatile) configured!\n",
      "Model: groq/llama-3.3-70b-versatile\n",
      "ðŸ“Š Free tier limits:\n",
      "   - Requests: 30/min, 1K/day\n",
      "   - Tokens: 12K/min, 100K/day\n",
      "\n",
      "Test: Capital of France = The capital of France is Paris.\n",
      "âœ… Groq connection verified!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## an...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    }
   ],
   "source": [
    "# Configure Groq with Llama 3.3 70B Versatile\n",
    "lm = dspy.LM(\n",
    "    'groq/llama-3.3-70b-versatile',\n",
    "    api_key=os.getenv('GROQ_API_KEY'),\n",
    "    max_tokens=1024,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Set as default LM\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "print(\"ðŸš€ Groq (Llama 3.3 70B Versatile) configured!\")\n",
    "print(f\"Model: {lm.model}\")\n",
    "print(f\"ðŸ“Š Free tier limits:\")\n",
    "print(f\"   - Requests: 30/min, 1K/day\")\n",
    "print(f\"   - Tokens: 12K/min, 100K/day\")\n",
    "\n",
    "# Quick test\n",
    "test = dspy.Predict(\"question -> answer\")\n",
    "result = test(question=\"What is the capital of France?\")\n",
    "print(f\"\\nTest: Capital of France = {result.answer}\")\n",
    "print(\"âœ… Groq connection verified!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2859a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š Mock Wikipedia search tool created\n",
      "\n",
      "ðŸ” Test search:\n",
      "  1. Python is a high-level programming language created by Guido van Rossum in 1991....\n",
      "  2. Python emphasizes code readability with significant whitespace and supports mult...\n",
      "  3. Python is widely used in web development, data science, and machine learning....\n"
     ]
    }
   ],
   "source": [
    "# Mock Wikipedia database (since public ColBERT servers are often down)\n",
    "WIKIPEDIA_MOCK = {\n",
    "    \"python programming\": [\n",
    "        \"Python is a high-level programming language created by Guido van Rossum in 1991.\",\n",
    "        \"Python emphasizes code readability with significant whitespace and supports multiple programming paradigms.\",\n",
    "        \"Python is widely used in web development, data science, and machine learning.\"\n",
    "    ],\n",
    "    \"machine learning\": [\n",
    "        \"Machine learning is a subset of artificial intelligence that enables systems to learn from data.\",\n",
    "        \"Common machine learning algorithms include decision trees, neural networks, and support vector machines.\",\n",
    "        \"Machine learning is used in recommendation systems, image recognition, and natural language processing.\"\n",
    "    ],\n",
    "    \"eiffel tower\": [\n",
    "        \"The Eiffel Tower is located in Paris, France and was completed in 1889.\",\n",
    "        \"The tower stands 330 meters tall and was designed by Gustave Eiffel.\",\n",
    "        \"It was initially criticized but is now one of the most visited monuments in the world.\"\n",
    "    ],\n",
    "    \"albert einstein\": [\n",
    "        \"Albert Einstein was a theoretical physicist born in 1879 in Germany.\",\n",
    "        \"He developed the theory of relativity, with E=mcÂ² being his most famous equation.\",\n",
    "        \"Einstein received the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def search_wikipedia(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search Wikipedia for relevant passages.\n",
    "    Returns top 3 most relevant text passages.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "    \n",
    "    Returns:\n",
    "        List of relevant text passages from Wikipedia\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Simple keyword matching\n",
    "    results = []\n",
    "    for topic, passages in WIKIPEDIA_MOCK.items():\n",
    "        if any(word in query_lower for word in topic.split()):\n",
    "            results.extend(passages)\n",
    "    \n",
    "    # If no matches, return general info\n",
    "    if not results:\n",
    "        results = [\"No specific information found. Please try a more specific query.\"]\n",
    "    \n",
    "    return results[:3]  # Return top 3 results\n",
    "\n",
    "\n",
    "print(\"ðŸ“š Mock Wikipedia search tool created\")\n",
    "print(\"\\nðŸ” Test search:\")\n",
    "test_results = search_wikipedia(\"What is Python?\")\n",
    "for i, result in enumerate(test_results, 1):\n",
    "    print(f\"  {i}. {result[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80457253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– ReAct RAG Agent created\n",
      "   - Signature: question -> answer\n",
      "   - Tools: search_wikipedia\n",
      "   - Max iterations: 5\n"
     ]
    }
   ],
   "source": [
    "# Create ReAct agent with Wikipedia search tool\n",
    "react_agent = dspy.ReAct(\n",
    "    signature=\"question -> answer\",\n",
    "    tools=[search_wikipedia],\n",
    "    max_iters=5\n",
    ")\n",
    "\n",
    "print(\"ðŸ¤– ReAct RAG Agent created\")\n",
    "print(\"   - Signature: question -> answer\")\n",
    "print(\"   - Tools: search_wikipedia\")\n",
    "print(\"   - Max iterations: 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7898fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Datasets created:\n",
      "   - Training set: 7 examples\n",
      "   - Validation set: 4 examples\n",
      "\n",
      "ðŸ“ Sample training example:\n",
      "   Question: What programming language was created by Guido van Rossum?\n",
      "   Answer: Python\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset (small dataset is sufficient for DSPy)\n",
    "trainset = [\n",
    "    dspy.Example(\n",
    "        question=\"What programming language was created by Guido van Rossum?\",\n",
    "        answer=\"Python\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"When was Python first released?\",\n",
    "        answer=\"1991\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"What is a subset of AI that learns from data?\",\n",
    "        answer=\"Machine learning\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"Where is the Eiffel Tower located?\",\n",
    "        answer=\"Paris\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"Who designed the Eiffel Tower?\",\n",
    "        answer=\"Gustave Eiffel\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"What year was Albert Einstein born?\",\n",
    "        answer=\"1879\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"What is Einstein's famous equation?\",\n",
    "        answer=\"E=mcÂ²\"\n",
    "    ).with_inputs(\"question\"),\n",
    "]\n",
    "\n",
    "# Create validation dataset\n",
    "valset = [\n",
    "    dspy.Example(\n",
    "        question=\"What does Python emphasize in code?\",\n",
    "        answer=\"readability\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"When was the Eiffel Tower completed?\",\n",
    "        answer=\"1889\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"What prize did Einstein win in 1921?\",\n",
    "        answer=\"Nobel Prize in Physics\"\n",
    "    ).with_inputs(\"question\"),\n",
    "    \n",
    "    dspy.Example(\n",
    "        question=\"What are common machine learning algorithms?\",\n",
    "        answer=\"decision trees\"\n",
    "    ).with_inputs(\"question\"),\n",
    "]\n",
    "\n",
    "print(f\"ðŸ“Š Datasets created:\")\n",
    "print(f\"   - Training set: {len(trainset)} examples\")\n",
    "print(f\"   - Validation set: {len(valset)} examples\")\n",
    "print(f\"\\nðŸ“ Sample training example:\")\n",
    "print(f\"   Question: {trainset[0].question}\")\n",
    "print(f\"   Answer: {trainset[0].answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667f41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing baseline agent (before optimization)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content=\"[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What programming language was created by Guido van Rossum?\n",
      "A: Python\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Where is the Eiffel Tower located?\n",
      "A: The Eiffel Tower is located in Paris, France.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Einstein's famous equation?\n",
      "A: E=mc^2\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§ª Testing baseline agent (before optimization)\\n\")\n",
    "\n",
    "# Test on a few examples\n",
    "test_questions = [\n",
    "    \"What programming language was created by Guido van Rossum?\",\n",
    "    \"Where is the Eiffel Tower located?\",\n",
    "    \"What is Einstein's famous equation?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    result = react_agent(question=question)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {result.answer}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5ec693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation metric defined: custom_metric (F1 >= 0.5)\n"
     ]
    }
   ],
   "source": [
    "# Use built-in exact match metric with flexibility\n",
    "def custom_metric(example, pred, trace=None):\n",
    "    \"\"\"\n",
    "    Custom metric that checks if prediction matches answer.\n",
    "    Allows partial matches for better optimization.\n",
    "    \"\"\"\n",
    "    # Use DSPy's built-in answer matching with partial match (F1 > 0.5)\n",
    "    return dspy.evaluate.answer_exact_match(\n",
    "        example, \n",
    "        pred, \n",
    "        trace=trace,\n",
    "        frac=0.5  # Allow 50% F1 match (more lenient than exact match)\n",
    "    )\n",
    "\n",
    "print(\"âœ… Evaluation metric defined: custom_metric (F1 >= 0.5)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24524005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ MIPROv2 Optimizer configured:\n",
      "   - Metric: custom_metric (F1 >= 0.5)\n",
      "   - Mode: light (faster, good for demos)\n",
      "   - Threads: 4\n",
      "\n",
      "ðŸ’¡ Optimization will:\n",
      "   1. Bootstrap few-shot examples from training data\n",
      "   2. Generate instruction candidates\n",
      "   3. Evaluate candidate programs on validation set\n",
      "   4. Select best combination using Bayesian optimization\n"
     ]
    }
   ],
   "source": [
    "# Initialize MIPROv2 optimizer\n",
    "optimizer = dspy.MIPROv2(\n",
    "    metric=custom_metric,\n",
    "    auto=\"light\",  # Options: \"light\", \"medium\", \"heavy\"\n",
    "    num_threads=4,  # Adjust based on your system\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ MIPROv2 Optimizer configured:\")\n",
    "print(\"   - Metric: custom_metric (F1 >= 0.5)\")\n",
    "print(\"   - Mode: light (faster, good for demos)\")\n",
    "print(\"   - Threads: 4\")\n",
    "print(\"\\nðŸ’¡ Optimization will:\")\n",
    "print(\"   1. Bootstrap few-shot examples from training data\")\n",
    "print(\"   2. Generate instruction candidates\")\n",
    "print(\"   3. Evaluate candidate programs on validation set\")\n",
    "print(\"   4. Select best combination using Bayesian optimization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ab9fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/04 14:22:47 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2026/02/04 14:22:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3bb18129190b47fca2f31d32d12046f7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current dspy workflow\n",
      "2026/02/04 14:22:47 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 7\n",
      "minibatch: False\n",
      "num_candidates: 3\n",
      "valset size: 4\n",
      "\n",
      "2026/02/04 14:22:47 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2026/02/04 14:22:47 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2026/02/04 14:22:47 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=3 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting optimization process...\n",
      "â³ This may take 2-5 minutes depending on dataset size\n",
      "\n",
      "Bootstrapping set 1/3\n",
      "Bootstrapping set 2/3\n",
      "Bootstrapping set 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2619a0d07ed64dae9a5b70e8a1336594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      " 14%|â–ˆâ–        | 1/7 [00:00<00:05,  1.03it/s]d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      " 29%|â–ˆâ–ˆâ–Š       | 2/7 [00:03<00:08,  1.69s/it]d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:05<00:08,  2.14s/it]d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content=\"[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:06<00:04,  1.65s/it]d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ne...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## re...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:08<00:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52aa9f33ca8641998033d9a3e9da52db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/04 14:22:56 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2026/02/04 14:22:56 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE CODE: StringSignature(question, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Given the fields `question`, produce the fields `answer`.\\n\\nYou will be given `question` and your goal is to finish with `answer`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>  Search Wikipedia for relevant passages.  Returns top 3 most relevant text passages.    Args:      query: Search query string    Returns:      List of relevant text passages from Wikipedia  </desc>. It takes arguments {'query': {'type': 'string'}} in JSON format.\\n(2) finish, whose description is <desc>Signals that the final outputs, i.e. `answer`, are now available and marks the task as complete.</desc>. It takes arguments {'kwargs': 'Any'} in JSON format.\"\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(question, trajectory -> reasoning, answer\n",
      "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Answer:', 'desc': '${answer}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        tools[\"finish\"] = Tool(\n",
      "            func=lambda **kwargs: \"Completed.\",\n",
      "            name=\"finish\",\n",
      "            desc=f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\",\n",
      "            args={},\n",
      "        )\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = getattr(tool, \"args\")\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields},\n",
      "            signature.instructions,\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def _format_trajectory(self, trajectory: dict[str, Any]):\n",
      "        adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "        trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "        return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self._call_with_potential_trajectory_truncation(self.react, trajectory, **input_args)\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                parsed_tool_args = {}\n",
      "                tool = self.tools[pred.next_tool_name]\n",
      "                for k, v in pred.next_tool_args.items():\n",
      "                    if hasattr(tool, \"arg_types\") and k in tool.arg_types:\n",
      "                        arg_type = tool.arg_types[k]\n",
      "                        if isinstance((origin := get_origin(arg_type) or arg_type), type) and issubclass(\n",
      "                            origin, BaseModel\n",
      "                        ):\n",
      "                            parsed_tool_args[k] = arg_type.model_validate(v)\n",
      "                            continue\n",
      "                    parsed_tool_args[k] = v\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**parsed_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self._call_with_potential_trajectory_truncation(self.extract, trajectory, **input_args)\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n",
      "    def _call_with_potential_trajectory_truncation(self, module, trajectory, **input_args):\n",
      "        while True:\n",
      "            try:\n",
      "                return module(\n",
      "                    **input_args,\n",
      "                    trajectory=self._format_trajectory(trajectory),\n",
      "                )\n",
      "            except ContextWindowExceededError:\n",
      "                logger.warning(\"Trajectory exceeded the context window, truncating the oldest tool call information.\")\n",
      "                trajectory = self.truncate_trajectory(trajectory)\n",
      "\n",
      "    def truncate_trajectory(self, trajectory):\n",
      "        \"\"\"Truncates the trajectory so that it fits in the context window.\n",
      "\n",
      "        Users can override this method to implement their own truncation logic.\n",
      "        \"\"\"\n",
      "        keys = list(trajectory.keys())\n",
      "        if len(keys) < 4:\n",
      "            # Every tool call has 4 keys: thought, tool_name, tool_args, and observation.\n",
      "            raise ValueError(\n",
      "                \"The trajectory is too long so your prompt exceeded the context window, but the trajectory cannot be \"\n",
      "                \"truncated because it only has one tool call.\"\n",
      "            )\n",
      "\n",
      "        for key in keys[:4]:\n",
      "            trajectory.pop(key)\n",
      "\n",
      "        return trajectory\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## ob...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## su...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n",
      "2026/02/04 14:22:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SUMMARY: The dataset consists of diverse question-answer pairs covering topics such as programming, history, science, and technology, with a focus on factual and concise questions. The straightforward syntax and broad range of domains suggest that the dataset could be used to train a general knowledge or trivia question-answering system. The model trained on this data could potentially handle a wide range of inquiries across various subjects.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: creative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\pydantic\\main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 5: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='[[ ## pr...er_specific_fields=None), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRAM DESCRIPTION: The provided program appears to be designed to solve tasks that involve answering questions by interleaving thought processes with the use of various tools, specifically a Wikipedia search tool and a finish tool. The program is structured around a reactive approach, where it iteratively generates the next thought, selects the next tool to use, and provides arguments for that tool based on the current state of the task. The program continues this process until it decides to use the \"finish\" tool, at which point it extracts the final answer based on the trajectory of thoughts, tool usage, and observations made during the task-solving process.\n",
      "\n",
      "The program utilizes a modular design, incorporating components such as a `ReAct` module that manages the reactive process, and tools like `search_wikipedia` that can be used to gather information relevant to the task at hand. The `ReAct` module is initialized with a signature that defines the input and output fields for the task, a list of available tools, and a maximum number of iterations. It uses a predictive model to generate the next steps in the task-solving process and can handle exceptions and trajectory truncation when the context window is exceeded.\n",
      "\n",
      "Overall, the program seems to be designed for tasks that require a combination of reasoning, information gathering, and decision-making to arrive at a final answer, and it leverages both human-like thought processes and automated tool usage to achieve this goal.\n",
      "Error getting program description. Running without program aware proposer.\n",
      "task_demos No task demos provided.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j7fskkkre6c8m8d7kk10szk5` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 9987, Requested 2773. Please try again in 3.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\llm_http_handler.py:221\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._make_common_sync_call\u001b[39m\u001b[34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, logging_obj, stream, signed_json_body)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     response = \u001b[43msync_httpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m            \u001b[49m\u001b[43msigned_json_body\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    227\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:1010\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mstatus_code\u001b[39m\u001b[33m\"\u001b[39m, e.response.status_code)\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:992\u001b[39m, in \u001b[36mHTTPHandler.post\u001b[39m\u001b[34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[39m\n\u001b[32m    991\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.send(req, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m992\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\main.py:2184\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   2182\u001b[39m             optional_params[k] = v\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m     response = \u001b[43mbase_llm_http_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshared_session\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshared_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_get_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# model call logging done inside the class as we make need to modify I/O to fit aleph alpha's requirements\u001b[39;49;00m\n\u001b[32m   2200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2201\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mgigachat\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2203\u001b[39m     \u001b[38;5;66;03m# GigaChat - Sber AI's LLM (Russia)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\llm_http_handler.py:524\u001b[39m, in \u001b[36mBaseLLMHTTPHandler.completion\u001b[39m\u001b[34m(self, model, messages, api_base, custom_llm_provider, model_response, encoding, logging_obj, optional_params, timeout, litellm_params, acompletion, stream, fake_stream, api_key, headers, client, provider_config, shared_session)\u001b[39m\n\u001b[32m    522\u001b[39m     sync_httpx_client = client\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_common_sync_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_httpx_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigned_json_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m provider_config.transform_response(\n\u001b[32m    536\u001b[39m     model=model,\n\u001b[32m    537\u001b[39m     raw_response=response,\n\u001b[32m   (...)\u001b[39m\u001b[32m    546\u001b[39m     json_mode=json_mode,\n\u001b[32m    547\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\llm_http_handler.py:246\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._make_common_sync_call\u001b[39m\u001b[34m(self, sync_httpx_client, provider_config, api_base, headers, data, timeout, litellm_params, logging_obj, stream, signed_json_body)\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\llm_http_handler.py:4505\u001b[39m, in \u001b[36mBaseLLMHTTPHandler._handle_error\u001b[39m\u001b[34m(self, e, provider_config)\u001b[39m\n\u001b[32m   4499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BaseLLMException(\n\u001b[32m   4500\u001b[39m         status_code=status_code,\n\u001b[32m   4501\u001b[39m         message=error_text,\n\u001b[32m   4502\u001b[39m         headers=error_headers,\n\u001b[32m   4503\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4505\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m provider_config.get_error_class(\n\u001b[32m   4506\u001b[39m     error_message=error_text,\n\u001b[32m   4507\u001b[39m     status_code=status_code,\n\u001b[32m   4508\u001b[39m     headers=error_headers,\n\u001b[32m   4509\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j7fskkkre6c8m8d7kk10szk5` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 10532, Requested 2773. Please try again in 6.525s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\utils.py:1563\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1562\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1563\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m end_time = datetime.datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\main.py:4242\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   4240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4241\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4242\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4245\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2378\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2377\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2378\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:382\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[32m    383\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRateLimitError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    384\u001b[39m         model=model,\n\u001b[32m    385\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    386\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    387\u001b[39m     )\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ExceptionCheckers.is_error_str_context_window_exceeded(error_str):\n",
      "\u001b[31mRateLimitError\u001b[39m: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j7fskkkre6c8m8d7kk10szk5` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 10532, Requested 2773. Please try again in 6.525s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâ³ This may take 2-5 minutes depending on dataset size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Compile optimized program\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m optimized_agent = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstudent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreact_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequires_permission_to_run\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Skip permission prompt\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ… Optimization complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:484\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    482\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:182\u001b[39m, in \u001b[36mwith_managed_run.<locals>.patch_with_managed_run\u001b[39m\u001b[34m(original, *args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     managed_run = create_managed_run()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     result = \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\mlflow\\dspy\\autolog.py:186\u001b[39m, in \u001b[36m_patched_compile\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# NB: Log a dummy run outputs such that \"Run\" tab is shown in the UI. Currently, the\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# GenAI experiment does not show the \"Run\" tab without this, which is critical gap for\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# DSPy users. This should be done BEFORE the compile call, because Run page is used\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# for tracking the compile progress, not only after finishing the compile.\u001b[39;00m\n\u001b[32m    184\u001b[39m log_dummy_model_outputs()\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m program = \u001b[43m_compile_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Save the state of the best model in json format\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# so that users can see the demonstrations and instructions.\u001b[39;00m\n\u001b[32m    189\u001b[39m save_dspy_module_state(program, \u001b[33m\"\u001b[39m\u001b[33mbest_model.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\mlflow\\dspy\\autolog.py:166\u001b[39m, in \u001b[36m_patched_compile.<locals>._compile_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_autologging_config(FLAVOR_NAME, \u001b[33m\"\u001b[39m\u001b[33mlog_traces_from_compile\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    168\u001b[39m         result = _trace_disabled_fn(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:475\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m         original_result = original(*_og_args, **_og_kwargs)\n\u001b[32m    473\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:426\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    424\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     original_fn_result = \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:472\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001b[32m    469\u001b[39m     disable_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m     reroute_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    471\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     original_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\teleprompt\\mipro_optimizer_v2.py:173\u001b[39m, in \u001b[36mMIPROv2.compile\u001b[39m\u001b[34m(self, student, trainset, teacher, valset, num_trials, max_bootstrapped_demos, max_labeled_demos, seed, minibatch, minibatch_size, minibatch_full_eval_steps, program_aware_proposer, data_aware_proposer, view_data_batch_size, tip_aware_proposer, fewshot_aware_proposer, requires_permission_to_run)\u001b[39m\n\u001b[32m    170\u001b[39m demo_candidates = \u001b[38;5;28mself\u001b[39m._bootstrap_fewshot_examples(program, trainset, seed, teacher)\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# Step 2: Propose instruction candidates\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m instruction_candidates = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_propose_instructions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mview_data_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram_aware_proposer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_aware_proposer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtip_aware_proposer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfewshot_aware_proposer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# If zero-shot, discard demos\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m zeroshot_opt:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\teleprompt\\mipro_optimizer_v2.py:451\u001b[39m, in \u001b[36mMIPROv2._propose_instructions\u001b[39m\u001b[34m(self, program, trainset, demo_candidates, view_data_batch_size, program_aware_proposer, data_aware_proposer, tip_aware_proposer, fewshot_aware_proposer)\u001b[39m\n\u001b[32m    433\u001b[39m proposer = GroundedProposer(\n\u001b[32m    434\u001b[39m     program=program,\n\u001b[32m    435\u001b[39m     trainset=trainset,\n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m     rng=\u001b[38;5;28mself\u001b[39m.rng\n\u001b[32m    448\u001b[39m )\n\u001b[32m    450\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProposing instructions...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m instruction_candidates = \u001b[43mproposer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpropose_instructions_for_program\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mN\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mT\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_temperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrial_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(program.predictors()):\n\u001b[32m    461\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProposed Instructions for Predictor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\propose\\grounded_proposer.py:358\u001b[39m, in \u001b[36mGroundedProposer.propose_instructions_for_program\u001b[39m\u001b[34m(self, trainset, program, demo_candidates, trial_logs, N, T, tip)\u001b[39m\n\u001b[32m    352\u001b[39m             \u001b[38;5;28mself\u001b[39m.use_tip = \u001b[38;5;28mbool\u001b[39m(\n\u001b[32m    353\u001b[39m                 selected_tip,\n\u001b[32m    354\u001b[39m             )\n\u001b[32m    355\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSelected tip: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_tip_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    357\u001b[39m         proposed_instructions[pred_i].append(\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropose_instruction_for_predictor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpred_i\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[43mT\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdemo_set_i\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemo_set_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtrial_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mselected_tip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    368\u001b[39m         )\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proposed_instructions\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\propose\\grounded_proposer.py:410\u001b[39m, in \u001b[36mGroundedProposer.propose_instruction_for_predictor\u001b[39m\u001b[34m(self, program, predictor, pred_i, T, demo_candidates, demo_set_i, trial_logs, tip)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dspy.settings.context(lm=\u001b[38;5;28mself\u001b[39m.prompt_model):\n\u001b[32m    409\u001b[39m     \u001b[38;5;28mself\u001b[39m.prompt_model.kwargs[\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m] = modified_temp\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     proposed_instruction = \u001b[43minstruction_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_i\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdemo_set_i\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemo_set_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_summary\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprevious_instructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstruction_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_demos_in_context\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_demos_in_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.proposed_instruction\n\u001b[32m    420\u001b[39m \u001b[38;5;28mself\u001b[39m.prompt_model.kwargs[\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m] = original_temp\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# Log the trace used to generate the new instruction, along with the new instruction itself\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\propose\\grounded_proposer.py:246\u001b[39m, in \u001b[36mGenerateModuleInstruction.forward\u001b[39m\u001b[34m(self, demo_candidates, pred_i, demo_set_i, program, previous_instructions, data_summary, num_demos_in_context, tip)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Generate an instruction for our chosen module\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtask_demos \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_demos\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m instruct = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_module_instruction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprogram_code_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogram_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_demos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask_demos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbasic_instruction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbasic_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprevious_instructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprevious_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m proposed_instruction = strip_prefix(instruct.proposed_instruction)\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dspy.Prediction(proposed_instruction=proposed_instruction)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:259\u001b[39m, in \u001b[36mwith_callbacks.<locals>.wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    258\u001b[39m     exception = e\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# Execute the end handlers even if the function call raises an exception.\u001b[39;00m\n\u001b[32m    262\u001b[39m     ACTIVE_CALL_ID.set(parent_call_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:255\u001b[39m, in \u001b[36mwith_callbacks.<locals>.wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    253\u001b[39m     \u001b[38;5;66;03m# Active ID must be set right before the function is called, not before calling the callbacks.\u001b[39;00m\n\u001b[32m    254\u001b[39m     ACTIVE_CALL_ID.set(call_id)\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     results = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\predict\\predict.py:67\u001b[39m, in \u001b[36mPredict.__call__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\predict\\predict.py:97\u001b[39m, in \u001b[36mPredict.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\n\u001b[32m     96\u001b[39m adapter = dspy.settings.adapter \u001b[38;5;129;01mor\u001b[39;00m dspy.ChatAdapter()\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m completions = \u001b[43madapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m pred = Prediction.from_completions(completions, signature=signature)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_trace\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m dspy.settings.trace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\adapters\\base.py:23\u001b[39m, in \u001b[36mAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     20\u001b[39m inputs_ = \u001b[38;5;28mself\u001b[39m.format(signature, demos, inputs)\n\u001b[32m     21\u001b[39m inputs_ = \u001b[38;5;28mdict\u001b[39m(prompt=inputs_) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs_, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(messages=inputs_)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m outputs = \u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m values = []\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:259\u001b[39m, in \u001b[36mwith_callbacks.<locals>.wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    258\u001b[39m     exception = e\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# Execute the end handlers even if the function call raises an exception.\u001b[39;00m\n\u001b[32m    262\u001b[39m     ACTIVE_CALL_ID.set(parent_call_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\utils\\callback.py:255\u001b[39m, in \u001b[36mwith_callbacks.<locals>.wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    253\u001b[39m     \u001b[38;5;66;03m# Active ID must be set right before the function is called, not before calling the callbacks.\u001b[39;00m\n\u001b[32m    254\u001b[39m     ACTIVE_CALL_ID.set(call_id)\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     results = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\clients\\lm.py:114\u001b[39m, in \u001b[36mLM.__call__\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_in_memory:\n\u001b[32m    112\u001b[39m     completion = cached_litellm_completion \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mchat\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cached_litellm_text_completion\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     response = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m     completion = litellm_completion \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mchat\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m litellm_text_completion\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\clients\\lm.py:314\u001b[39m, in \u001b[36mrequest_cache.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(request, *args, **kwargs)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;66;03m# If the cache key cannot be computed (e.g. because it contains a value that cannot\u001b[39;00m\n\u001b[32m    312\u001b[39m     \u001b[38;5;66;03m# be converted to JSON), bypass the cache and call the target function directly\u001b[39;00m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(request, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\cachetools\\_cached.py:178\u001b[39m, in \u001b[36m_locked.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    177\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# key not found\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m v = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    181\u001b[39m         \u001b[38;5;66;03m# possible race condition: see above\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\clients\\lm.py:304\u001b[39m, in \u001b[36mrequest_cache.<locals>.decorator.<locals>.func_cached\u001b[39m\u001b[34m(key, request, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;129m@cached\u001b[39m(\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# NB: cachetools doesn't support maxsize=None; it recommends using float(\"inf\") instead\u001b[39;00m\n\u001b[32m    297\u001b[39m     cache=LRUCache(maxsize=maxsize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m )\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_cached\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, request: Dict[\u001b[38;5;28mstr\u001b[39m, Any], *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\clients\\lm.py:323\u001b[39m, in \u001b[36mcached_litellm_completion\u001b[39m\u001b[34m(request, num_retries)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;129m@request_cache\u001b[39m(maxsize=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_litellm_completion\u001b[39m(request: Dict[\u001b[38;5;28mstr\u001b[39m, Any], num_retries: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno-cache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno-store\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\dspy\\clients\\lm.py:341\u001b[39m, in \u001b[36mlitellm_completion\u001b[39m\u001b[34m(request, num_retries, cache)\u001b[39m\n\u001b[32m    339\u001b[39m stream = dspy.settings.send_stream\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mretry_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;66;03m# The stream is already opened, and will be closed by the caller.\u001b[39;00m\n\u001b[32m    348\u001b[39m stream = cast(MemoryObjectSendStream, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\utils.py:1687\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1682\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(e, openai.APIError)\n\u001b[32m   1683\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, openai.Timeout)\n\u001b[32m   1684\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, openai.APIConnectionError)\n\u001b[32m   1685\u001b[39m     ):\n\u001b[32m   1686\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_retries\u001b[39m\u001b[33m\"\u001b[39m] = num_retries\n\u001b[32m-> \u001b[39m\u001b[32m1687\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1689\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(e, litellm.exceptions.ContextWindowExceededError)\n\u001b[32m   1690\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m context_window_fallback_dict\n\u001b[32m   1691\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m context_window_fallback_dict\n\u001b[32m   1692\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_litellm_router_call\n\u001b[32m   1693\u001b[39m ):\n\u001b[32m   1694\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\main.py:4280\u001b[39m, in \u001b[36mcompletion_with_retries\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   4276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4277\u001b[39m     retryer = tenacity.Retrying(\n\u001b[32m   4278\u001b[39m         stop=tenacity.stop_after_attempt(num_retries), reraise=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   4279\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4280\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretryer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py:443\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py:395\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    397\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    398\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\utils.py:1742\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1739\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1740\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1741\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\utils.py:1563\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1561\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1562\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1563\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1566\u001b[39m     kwargs=kwargs,\n\u001b[32m   1567\u001b[39m     call_type=call_type,\n\u001b[32m   1568\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\main.py:4242\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   4239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   4240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4241\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4242\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4245\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2378\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2377\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2378\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2379\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2380\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:382\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ExceptionCheckers.is_error_str_rate_limit(error_str):\n\u001b[32m    381\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[32m    383\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRateLimitError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    384\u001b[39m         model=model,\n\u001b[32m    385\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    386\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    387\u001b[39m     )\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ExceptionCheckers.is_error_str_context_window_exceeded(error_str):\n\u001b[32m    389\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j7fskkkre6c8m8d7kk10szk5` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 9987, Requested 2773. Please try again in 3.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Starting optimization process...\")\n",
    "print(\"â³ This may take 2-5 minutes depending on dataset size\\n\")\n",
    "\n",
    "# Compile optimized program\n",
    "optimized_agent = optimizer.compile(\n",
    "    student=react_agent,\n",
    "    trainset=trainset,\n",
    "    valset=valset,\n",
    "    requires_permission_to_run=False  # Skip permission prompt\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Optimization complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
