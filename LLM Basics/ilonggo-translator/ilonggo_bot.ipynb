{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5d6d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\User\\Desktop\\Acads\\4th Year\\TwoTabs Dir\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Import all required libraries\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings  # ‚úÖ Local embeddings\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5433138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key loaded\n",
      "‚úÖ Groq API key loaded\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Load API keys from .env file\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Verify keys are loaded\n",
    "gemini_key = os.getenv('GEMINI_API_KEY')\n",
    "groq_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if gemini_key:\n",
    "    print(\"‚úÖ Gemini API key loaded\")\n",
    "if groq_key:\n",
    "    print(\"‚úÖ Groq API key loaded\")\n",
    "    \n",
    "if not gemini_key and not groq_key:\n",
    "    print(\"‚ö†Ô∏è No API keys found! Create .env file with your keys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c2711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using Groq Llama 3.1 8B for chat\n",
      "   - Free tier: 14,400 requests/day (720x more than Gemini!)\n",
      "   - Model: llama-3.1-8b-instant\n",
      "\n",
      "üì• Loading local embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Client\\AppData\\Local\\Temp\\ipykernel_27976\\993052461.py:19: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f2ab42ffe64d8cb07810f9383a1a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Setup complete!\n",
      "   - LLM: Groq Llama 3.1 8B (14,400/day)\n",
      "   - Embeddings: Local (unlimited)\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Configure LLM with GROQ (14,400 requests/day!)\n",
    "\n",
    "# Use Groq for unlimited free usage\n",
    "MODEL_CHOICE = \"groq\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    groq_api_key=os.getenv('GROQ_API_KEY'),\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"üöÄ Using Groq Llama 3.1 8B for chat\")\n",
    "print(\"   - Free tier: 14,400 requests/day (720x more than Gemini!)\")\n",
    "print(f\"   - Model: {llm.model_name}\")\n",
    "\n",
    "# LOCAL EMBEDDINGS (still unlimited)\n",
    "print(\"\\nüì• Loading local embedding model...\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")\n",
    "print(\"   - LLM: Groq Llama 3.1 8B (14,400/day)\")\n",
    "print(\"   - Embeddings: Local (unlimited)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89335096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loading Ilonggo dictionaries from 'dictionaries/' folder...\n",
      "   (Any PDF filename works - all PDFs will be loaded)\n",
      "\n",
      "‚úÖ Loaded 596 pages from PDF dictionaries\n",
      "\n",
      "üìñ Sample text from first page:\n",
      "English ‚Äì Hiligaynon (Ilongo)\n",
      "a ( indefinite article) isa \n",
      "aback ( to be taken aback) palak \n",
      "abandon pabayaan , abandonar \n",
      "abandoned sim-ong \n",
      "abatoir ihawan \n",
      "abbreviation lip-ot \n",
      "ABC abakada \n",
      "abdomen ...\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Load all PDF dictionaries from 'dictionaries/' folder\n",
    "# ‚ö†Ô∏è IMPORTANT: Put your PDF files in 'dictionaries/' folder first!\n",
    "\n",
    "print(\"üìö Loading Ilonggo dictionaries from 'dictionaries/' folder...\")\n",
    "print(\"   (Any PDF filename works - all PDFs will be loaded)\")\n",
    "\n",
    "# Load all PDFs from dictionaries folder\n",
    "loader = PyPDFDirectoryLoader(\"./dictionaries/\")\n",
    "\n",
    "try:\n",
    "    documents = loader.load()\n",
    "    print(f\"\\n‚úÖ Loaded {len(documents)} pages from PDF dictionaries\")\n",
    "    \n",
    "    # Show first 200 characters to verify\n",
    "    if documents:\n",
    "        print(f\"\\nüìñ Sample text from first page:\")\n",
    "        print(f\"{documents[0].page_content[:200]}...\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No PDFs found!\")\n",
    "        print(\"   1. Create 'dictionaries/' folder in project root\")\n",
    "        print(\"   2. Add your Ilonggo dictionary PDFs to it\")\n",
    "        print(\"   3. Run this cell again\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading PDFs: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Make sure 'dictionaries/' folder exists\")\n",
    "    print(\"  2. Check PDFs are not password-protected\")\n",
    "    print(\"  3. Verify file paths are correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3a16d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Splitting dictionary into chunks...\n",
      "\n",
      "‚úÖ Created 9622 searchable chunks\n",
      "   - Average chunk size: ~500 characters\n",
      "   - Overlap: 50 characters\n",
      "\n",
      "üìù Sample chunk preview:\n",
      "English ‚Äì Hiligaynon (Ilongo)\n",
      "a ( indefinite article) isa \n",
      "aback ( to be taken aback) palak \n",
      "abandon pabayaan , abandonar \n",
      "abandoned sim-ong \n",
      "abatoir ...\n",
      "\n",
      "üìä Statistics:\n",
      "   - Total chunks: 9622\n",
      "   - Total characters: 4,501,736\n",
      "   - Average chunk size: 467 chars\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Split dictionary pages into searchable chunks\n",
    "\n",
    "print(\"‚úÇÔ∏è Splitting dictionary into chunks...\")\n",
    "\n",
    "# Configure text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,        # Small chunks for dictionary entries\n",
    "    chunk_overlap=50,      # Overlap to avoid cutting words mid-definition\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],  # Split on paragraphs first\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(chunks)} searchable chunks\")\n",
    "print(f\"   - Average chunk size: ~500 characters\")\n",
    "print(f\"   - Overlap: 50 characters\")\n",
    "\n",
    "# Show sample chunk\n",
    "print(f\"\\nüìù Sample chunk preview:\")\n",
    "print(f\"{chunks[0].page_content[:150]}...\")\n",
    "\n",
    "# Show statistics\n",
    "total_chars = sum(len(chunk.page_content) for chunk in chunks)\n",
    "avg_chunk_size = total_chars // len(chunks) if chunks else 0\n",
    "print(f\"\\nüìä Statistics:\")\n",
    "print(f\"   - Total chunks: {len(chunks)}\")\n",
    "print(f\"   - Total characters: {total_chars:,}\")\n",
    "print(f\"   - Average chunk size: {avg_chunk_size} chars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c0cb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Creating searchable vector database with FAISS...\n",
      "‚è≥ This may take 1-3 minutes for large dictionaries...\n",
      "   (Using LOCAL embeddings - no rate limits!)\n",
      "\n",
      "‚úÖ Vector database created with FAISS!\n",
      "   - Time taken: 122.8 seconds\n",
      "   - Stored in: ./faiss_index/\n",
      "   - Indexed 9622 dictionary entries\n",
      "   - Total vectors: 9622\n",
      "\n",
      "üí° Next time, use Cell 6B to load instantly from disk!\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Create searchable vector database with FAISS and local embeddings\n",
    "# This creates the RAG index - run this ONCE, then use Cell 6B to reload\n",
    "\n",
    "print(\"üîç Creating searchable vector database with FAISS...\")\n",
    "print(\"‚è≥ This may take 1-3 minutes for large dictionaries...\")\n",
    "print(\"   (Using LOCAL embeddings - no rate limits!)\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create vector store with FAISS\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Save to disk (so you can reload later without reprocessing)\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Vector database created with FAISS!\")\n",
    "print(f\"   - Time taken: {elapsed_time:.1f} seconds\")\n",
    "print(f\"   - Stored in: ./faiss_index/\")\n",
    "print(f\"   - Indexed {len(chunks)} dictionary entries\")\n",
    "print(f\"   - Total vectors: {vectorstore.index.ntotal}\")\n",
    "print(\"\\nüí° Next time, use Cell 6B to load instantly from disk!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c78d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading existing FAISS vector database from disk...\n",
      "\n",
      "‚úÖ Vector database loaded from disk!\n",
      "   - Location: ./faiss_index/\n",
      "   - Total vectors: 9622\n",
      "   - Ready to use!\n",
      "\n",
      "üí° This is much faster than re-processing PDFs!\n"
     ]
    }
   ],
   "source": [
    "# CELL 6B: Load existing FAISS database from disk\n",
    "# Use this INSTEAD of Cell 6 after you've created the database once\n",
    "# This is much faster than recreating the database!\n",
    "\n",
    "print(\"üîÑ Loading existing FAISS vector database from disk...\")\n",
    "\n",
    "try:\n",
    "    vectorstore = FAISS.load_local(\n",
    "        \"faiss_index\", \n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True  # Safe for your own data\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Vector database loaded from disk!\")\n",
    "    print(f\"   - Location: ./faiss_index/\")\n",
    "    print(f\"   - Total vectors: {vectorstore.index.ntotal}\")\n",
    "    print(\"   - Ready to use!\")\n",
    "    print(\"\\nüí° This is much faster than re-processing PDFs!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\n‚ùå FAISS index not found!\")\n",
    "    print(\"   Run Cell 6 first to create the database.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading database: {e}\")\n",
    "    print(\"   You may need to recreate it with Cell 6.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "068bec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Building retrieval chain...\n",
      "\n",
      "‚úÖ Ilonggo Translator Chatbot is ready!\n",
      "\n",
      "üí¨ Example questions you can ask:\n",
      "   - 'What does mahal mean?'\n",
      "   - 'How do you say love in Ilonggo?'\n",
      "   - 'Translate pagkaon to English'\n",
      "   - 'What is the Ilonggo word for beautiful?'\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Build the translation chain using LangChain Expression Language (LCEL)\n",
    "\n",
    "print(\"üîó Building retrieval chain...\")\n",
    "\n",
    "# Create retriever from vectorstore\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Return top 3 most relevant dictionary entries\n",
    ")\n",
    "\n",
    "# Custom prompt template for translation\n",
    "template = \"\"\"You are an Ilonggo-English dictionary assistant. Use the dictionary entries below to help translate.\n",
    "\n",
    "Dictionary Context:\n",
    "{context}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Instructions:\n",
    "- If the word is in the dictionary, provide the definition/translation\n",
    "- If it's English to Ilonggo, search for the English word\n",
    "- If it's Ilonggo to English, search for the Ilonggo word\n",
    "- If not found, say \"I couldn't find that word in the dictionary\"\n",
    "- Be helpful, friendly, and concise\n",
    "- Provide pronunciation help if available in the dictionary\n",
    "\n",
    "Translation:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Function to format retrieved documents\n",
    "def format_docs(docs):\n",
    "    \"\"\"Combine multiple dictionary entries into context\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build the translation chain using LCEL\n",
    "translator_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Ilonggo Translator Chatbot is ready!\")\n",
    "print(\"\\nüí¨ Example questions you can ask:\")\n",
    "print(\"   - 'What does mahal mean?'\")\n",
    "print(\"   - 'How do you say love in Ilonggo?'\")\n",
    "print(\"   - 'Translate pagkaon to English'\")\n",
    "print(\"   - 'What is the Ilonggo word for beautiful?'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efe17d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running test translations...\n",
      "\n",
      "\n",
      "============================================================\n",
      "üáµüá≠ YOU: What does 'mahal' mean in English?\n",
      "============================================================\n",
      "üí¨ TRANSLATOR: The word 'mahal' is found in the dictionary. \n",
      "\n",
      "According to the dictionary, 'mahal' means: \n",
      "Dear, high-priced, expensive, costly, precious, esteemed, valuable, estimable; to make or become dear, cost much; to appreciate, esteem highly.\n",
      "\n",
      "Pronunciation: mah-HAHL\n",
      "\n",
      "Note: The dictionary also has a diminutive form 'mah√°l-mah√°l' which means rather dear, expensive, costly, precious, valuable.\n",
      "\n",
      "üìö Used 3 dictionary entries\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üáµüá≠ YOU: How do you say 'hello' in Ilonggo?\n",
      "============================================================\n",
      "üí¨ TRANSLATOR: I'd be happy to help you with your Ilonggo-English dictionary questions.\n",
      "\n",
      "However, I noticed you didn't ask a question about a specific word. Could you please ask how to say \"hello\" in Ilonggo, and I'll be more than happy to assist you?\n",
      "\n",
      "If you'd like to ask a different question, feel free to do so, and I'll do my best to help.\n",
      "\n",
      "(If you'd like to ask about a specific word, just let me know, and I'll be happy to help with that too!)\n",
      "\n",
      "üìö Used 3 dictionary entries\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üáµüá≠ YOU: Translate 'kumusta' to English\n",
      "============================================================\n",
      "üí¨ TRANSLATOR: I'd be happy to help you with the translation.\n",
      "\n",
      "The word you're looking for is \"kumusta\". Unfortunately, I couldn't find \"kumusta\" in the dictionary. However, I think I can help you with a possible translation.\n",
      "\n",
      "In Ilonggo, \"kumusta\" is actually a verb that means \"to ask how someone is doing\" or \"to inquire about someone's well-being\". It's a common phrase used in Ilonggo culture.\n",
      "\n",
      "If you're looking for a direct translation, it's similar to asking \"how are you?\" in English.\n",
      "\n",
      "If you'd like to know more about the verb \"kumusta\" or its usage in Ilonggo culture, feel free to ask!\n",
      "\n",
      "üìö Used 3 dictionary entries\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Test function to translate and show results\n",
    "\n",
    "def translate(question):\n",
    "    \"\"\"\n",
    "    Translate between Ilonggo and English\n",
    "    Shows the answer and source documents used\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üáµüá≠ YOU: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get translation\n",
    "    answer = translator_chain.invoke(question)\n",
    "    \n",
    "    print(f\"üí¨ TRANSLATOR: {answer}\")\n",
    "    \n",
    "    # Show source documents used\n",
    "    docs = retriever.invoke(question)\n",
    "    print(f\"\\nüìö Used {len(docs)} dictionary entries\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return answer, docs\n",
    "\n",
    "# Run test queries\n",
    "test_queries = [\n",
    "    \"What does 'mahal' mean in English?\",\n",
    "    \"How do you say 'hello' in Ilonggo?\",\n",
    "    \"Translate 'kumusta' to English\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Running test translations...\\n\")\n",
    "for query in test_queries:\n",
    "    translate(query)\n",
    "    print()  # Add spacing between tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "089e4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üáµüá≠ ILONGGO DICTIONARY TRANSLATOR\n",
      "============================================================\n",
      "Ask me to translate between Ilonggo and English!\n",
      "\n",
      "Commands:\n",
      "  - Type your question to translate\n",
      "  - Type 'sources' to see dictionary sources for last query\n",
      "  - Type 'quit' or 'exit' to end\n",
      "============================================================\n",
      "\n",
      "üí¨ Translator: I'd be happy to help you with the translation.\n",
      "\n",
      "The word \"nakatungdan\" is in the dictionary. \n",
      "\n",
      "According to the dictionary, \"nakatungdan\" is the past tense of the word \"tungdan,\" which is not directly listed in the dictionary. However, the word \"tungdan\" seems to be related to the word \"t√°hud,\" which means \"To agree, pull well together, live in peace or amity.\" \n",
      "\n",
      "Since \"t√°hud\" is the closest match, I'll provide the translation for \"nakatungdan\" based on its possible relationship with \"t√°hud.\"\n",
      "\n",
      "If \"nakatungdan\" is indeed related to \"t√°hud,\" it might mean \"to agree\" or \"to be in harmony\" in the past tense. However, please note that this is an educated guess, and the actual meaning of \"nakatungdan\" might be different.\n",
      "\n",
      "If you have more context or information about the word \"nakatungdan,\" I'd be happy to try and provide a more accurate translation.\n",
      "\n",
      "üìñ Found 3 relevant entries:\n",
      "============================================================\n",
      "\n",
      "Source 1:\n",
      "(boosted) the price of‚Äî, each earthen rice-\n",
      "pot (by Ô¨Åve centavos).\n",
      "pamaha√≥n, (B) Freq. of baha√≥n‚Äîto\n",
      "sneeze. (cf. pang√°tsi).\n",
      "pam√°hat, Freq. of p√°hat‚Äîto divide, cut\n",
      "up, distribute.\n",
      "pam√°haw, Breakfast, afternoon tea, light\n",
      "repast; to have breakfast, to breakfast, take\n",
      "a light repast. Nam√°haw (Nagpam√°ha\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 2:\n",
      "me. Ginat√°hud si√° sing dak√ª bang√∫d sang\n",
      "mat√°rung n√≠ya nga bat√°san. He is held in\n",
      "great reverence on account of his honesty\n",
      "(righteous conduct). Ginat√°hud ko si√°, kay\n",
      "talah√∫ron (si√°). I honour him, because he\n",
      "is worthy of honour. (cf. tah√¢,\n",
      "matinah√∫ron, katahur√°n, talah√∫ron,\n",
      "tinat√°hud).\n",
      "t√°hud, To agr\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 3:\n",
      "b√∫tkon. His arm is twisted. (cf. kiw√Æ, hiw√Æ,\n",
      "sambig√Æ).\n",
      "paki√°byan, To make friends, to befriend,\n",
      "try to be friends, be friendly, be pleasant or\n",
      "obliging in social intercourse. (paki‚Äî,\n",
      "√°byan).\n",
      "pakiad√≥r, A contractor, whole-sale\n",
      "dealer, one who undertakes a job with full\n",
      "responsibility. (cf. paki√°w and\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "üí¨ Translator: I'd be happy to help you with the translation.\n",
      "\n",
      "The word \"nasidlangan\" seems to be a combination of \"nasig-\" and \"langan\". \n",
      "\n",
      "According to the dictionary, \"nasig-\" is a prefix that means \"all\" or \"together\", and \"langan\" is not directly found in the dictionary. However, \"lan√∫s\" is found, which means \"Spoilt, rotten, overripe, putrid, tainted, rancid, said of coconuts, oil, peas and beans, etc.\"\n",
      "\n",
      "Considering the prefix \"nasig-\", I'm going to take a guess that \"nasidlangan\" might be related to \"nasig-\" and \"langan\" could be a variation of \"lan√∫s\". \n",
      "\n",
      "If that's the case, a possible translation for \"nasidlangan\" could be \"They all spoiled\" or \"They all became rotten\".\n",
      "\n",
      "Please note that this is just a guess, and I couldn't find a direct match for \"nasidlangan\" in the dictionary. If you have more context or information about the word, I'd be happy to help you further.\n",
      "\n",
      "Pronunciation for \"nasidlangan\" would be \"na-sid-lan-gan\" with emphasis on the second syllable (id).\n",
      "\n",
      "üìñ Found 3 relevant entries:\n",
      "============================================================\n",
      "\n",
      "Source 1:\n",
      "and pagpasig- for the inÔ¨Ånitive.\n",
      "Nasigkal√°dlaw sil√° nga tan√°n. They all of\n",
      "them laughed together. Nasigpalang√≠t√†\n",
      "sil√° sing palam√∫gnan. They were all\n",
      "looking for work. Nasigal√°mot sil√°,\n",
      "nasigkal√°wat sil√°, etc. They all\n",
      "contributed, they all went to Holy\n",
      "Communion, etc. (nasi- id.).\n",
      "nasimy√©nto, (Sp. n\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 2:\n",
      "Nalanus√°n ak√≥ sing pil√° ka sip√Æ nga\n",
      "s√°ging sa bak√°g. Several clusters of my\n",
      "bananas got bruised in the basket. (cf.\n",
      "h√°nog, han√≥g, lan√≥g).\n",
      "lan√∫s, (B) Spoilt, rotten, overripe, putrid,\n",
      "tainted, rancid, said of coconuts, oil, peas\n",
      "and beans, etc. (cf. lu√≥, lan√≥ng, tan√°ng).\n",
      "l√°nya, (Sp. la√±a) Brace, clam\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 3:\n",
      "English ‚Äì Hiligaynon (Ilongo)\n",
      "nation nasyon , pungsod \n",
      "nations ( states, powers) kapungsuran \n",
      "national pungsudnon \n",
      "nationalistic ( adjective) makig-pungsod\n",
      "nationality nasyonalidad \n",
      "nationality ( noun) kaliwatan \n",
      "native tumandok , tinubo \n",
      "native country natuboan , natawohan \n",
      "nativity ( noun) kapanga\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "üí¨ Translator: I'd be happy to help you with the word \"wayang\".\n",
      "\n",
      "Unfortunately, I couldn't find the word \"wayang\" in the provided dictionary. However, I think it might be related to the word \"way\" which is defined as \"nagapalamuti\" or \"path\". \n",
      "\n",
      "If you could provide more context or information about the word \"wayang\", I might be able to help you better.\n",
      "\n",
      "üìñ Found 3 relevant entries:\n",
      "============================================================\n",
      "\n",
      "Source 1:\n",
      "way ( noun) nagapalamuti\n",
      "waylay ( verb) dalan , paagi \n",
      "wayward ( adjective) dalamhak\n",
      "55\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 2:\n",
      "Visayan-English Dictionary ur√°ngul ‚Äì √∫so\n",
      "531\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 3:\n",
      "bu√°k, Slice, portion, share, division (of a\n",
      "pomelo, orange, or the like). (cf. til√≥d).\n",
      "b√∫ang, A lunatic, fool, idiot, ass, etc., etc.;\n",
      "to be or become a fool, stupid, etc., etc.\n",
      "S√°n-o pa ik√°w magb√∫ang? Since when did\n",
      "you become such an ass? Ind√¨ mo\n",
      "pagbu√°ngon ang √≠mo nga kas√∫bung. Don‚Äôt\n",
      "make a fool \n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "üí¨ Translator: To offer as a sacrifice is \"halad\" in Ilonggo. \n",
      "\n",
      "According to the dictionary, \"halad\" is defined as \"sacrifice\".\n",
      "\n",
      "üìñ Found 3 relevant entries:\n",
      "============================================================\n",
      "\n",
      "Source 1:\n",
      "sacrifice halad \n",
      "sacristy sakristiya \n",
      "sad masubo \n",
      "sad ( adjective) masinulub-on, mamingawon\n",
      "saddle ( noun) silya sang kabayo \n",
      "saddle ( verb) silyahan\n",
      "sadness ( noun) kasulub-on, kamingawan\n",
      "safe ( adjective) hilway , luas \n",
      "safe ( bank) talagoan-pilak \n",
      "safety ( noun) kahiwayan, kaluasan \n",
      "sagacious mai\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 2:\n",
      "oneself with‚Äî, a childless couple (in order\n",
      "to obtain some favours, inherit their\n",
      "property, etc.). (cf. b√°w-as, pam√°w-as).\n",
      "pakib√¥, Caus. of kib√¥‚Äîto beat, throb.\n",
      "Am√≥ in√≠ ang nagpakib√¥ sing mad√°sig sang\n",
      "√≠ya nga tagipos√≥on. This was what made\n",
      "his heart beat fast. This was what set his\n",
      "heart beating fas\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Source 3:\n",
      "or application; be a good boy. (cf. pan√∫t√≤).\n",
      "patut√∫s, To yield, give in, submit, etc. See\n",
      "patubal√≠ng, paub√°g.\n",
      "pat√∫wad, To make gallop, to gallop\n",
      "(transitive), put to the gallop or canter.\n",
      "Patuw√°ra ang kab√°yo. Gallop the horse.\n",
      "Ginpat√∫wad n√≠ya ang karab√°w. He made\n",
      "the buffalo run fast. (pa, t√∫wad).\n",
      "p\n",
      "...\n",
      "------------------------------------------------------------\n",
      "\n",
      "üëã Salamat! (Thank you!)\n",
      "Goodbye! üáµüá≠\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Interactive chat loop for continuous translation\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üáµüá≠ ILONGGO DICTIONARY TRANSLATOR\")\n",
    "print(\"=\"*60)\n",
    "print(\"Ask me to translate between Ilonggo and English!\")\n",
    "print(\"\\nCommands:\")\n",
    "print(\"  - Type your question to translate\")\n",
    "print(\"  - Type 'sources' to see dictionary sources for last query\")\n",
    "print(\"  - Type 'quit' or 'exit' to end\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Store last query for source viewing\n",
    "last_query = None\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nüáµüá≠ You: \").strip()\n",
    "    \n",
    "    # Check for exit commands\n",
    "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"\\nüëã Salamat! (Thank you!)\")\n",
    "        print(\"Goodbye! üáµüá≠\")\n",
    "        break\n",
    "    \n",
    "    # Skip empty input\n",
    "    if not user_input:\n",
    "        continue\n",
    "    \n",
    "    # Special command to show sources from last query\n",
    "    if user_input.lower() == 'sources':\n",
    "        if last_query:\n",
    "            docs = retriever.invoke(last_query)\n",
    "            print(f\"\\nüìö Dictionary sources for '{last_query}':\")\n",
    "            print(\"=\"*60)\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                print(f\"\\nSource {i}:\")\n",
    "                print(doc.page_content[:300])\n",
    "                print(\"-\"*60)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No previous query. Ask a question first!\")\n",
    "        continue\n",
    "    \n",
    "    # Process translation\n",
    "    try:\n",
    "        # Get translation\n",
    "        answer = translator_chain.invoke(user_input)\n",
    "        print(f\"\\nüí¨ Translator: {answer}\")\n",
    "        \n",
    "        # Store query for potential source viewing\n",
    "        last_query = user_input\n",
    "        \n",
    "        # Ask if user wants to see sources\n",
    "        show_sources = input(\"\\nüìö Show dictionary sources? (y/n): \").strip().lower()\n",
    "        if show_sources == 'y':\n",
    "            docs = retriever.invoke(user_input)\n",
    "            print(f\"\\nüìñ Found {len(docs)} relevant entries:\")\n",
    "            print(\"=\"*60)\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                print(f\"\\nSource {i}:\")\n",
    "                print(doc.page_content[:300])\n",
    "                if len(doc.page_content) > 300:\n",
    "                    print(\"...\")\n",
    "                print(\"-\"*60)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        print(\"Try rephrasing your question or check your connection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "210b4c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Search function ready!\n",
      "\n",
      "Usage examples:\n",
      "  search_dictionary('love', k=3)\n",
      "  search_dictionary('kumusta', k=5)\n",
      "  search_dictionary('maganda', k=2)\n"
     ]
    }
   ],
   "source": [
    "# CELL 10: Direct search function for exploring the dictionary\n",
    "\n",
    "def search_dictionary(word, k=5):\n",
    "    \"\"\"\n",
    "    Search the vector database directly for specific words\n",
    "    Returns the k most similar dictionary entries\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(word, k=k)\n",
    "    \n",
    "    print(f\"\\nüîç Searching dictionary for: '{word}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"‚ùå No matches found\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(results)} relevant entries:\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"üìñ Result {i} (Relevance rank: {i}/{k}):\")\n",
    "        print(\"-\"*60)\n",
    "        print(doc.page_content)\n",
    "        print(\"-\"*60)\n",
    "        print()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment to test):\n",
    "# search_dictionary(\"mahal\", k=3)\n",
    "\n",
    "print(\"‚úÖ Search function ready!\")\n",
    "print(\"\\nUsage examples:\")\n",
    "print(\"  search_dictionary('love', k=3)\")\n",
    "print(\"  search_dictionary('kumusta', k=5)\")\n",
    "print(\"  search_dictionary('maganda', k=2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4976da64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Batch translation function ready!\n",
      "\n",
      "Usage:\n",
      "  words = ['mahal', 'kumusta', 'salamat']\n",
      "  results = batch_translate(words)\n"
     ]
    }
   ],
   "source": [
    "# CELL 11: Batch translate multiple words at once\n",
    "\n",
    "def batch_translate(words_list):\n",
    "    \"\"\"\n",
    "    Translate multiple words in one go\n",
    "    Useful for learning vocabulary lists\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìù Batch Translation ({len(words_list)} words)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, word in enumerate(words_list, 1):\n",
    "        print(f\"\\n{i}. Translating '{word}'...\")\n",
    "        try:\n",
    "            answer = translator_chain.invoke(f\"What does {word} mean?\")\n",
    "            results.append({\"word\": word, \"translation\": answer, \"status\": \"success\"})\n",
    "            print(f\"   ‚úÖ {answer[:100]}{'...' if len(answer) > 100 else ''}\")\n",
    "        except Exception as e:\n",
    "            results.append({\"word\": word, \"translation\": str(e), \"status\": \"error\"})\n",
    "            print(f\"   ‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ Batch translation complete!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment to test):\n",
    "# words_to_translate = [\"mahal\", \"kumusta\", \"salamat\", \"maganda\"]\n",
    "# results = batch_translate(words_to_translate)\n",
    "\n",
    "print(\"‚úÖ Batch translation function ready!\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  words = ['mahal', 'kumusta', 'salamat']\")\n",
    "print(\"  results = batch_translate(words)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "208f6467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running complete system diagnostics...\n",
      "\n",
      "============================================================\n",
      "Test 1: Vector Database\n",
      "‚úÖ Vector database operational\n",
      "   - Total vectors: 9622\n",
      "   - Test query returned: 1 results\n",
      "\n",
      "Test 2: Retriever\n",
      "‚úÖ Retriever operational\n",
      "   - Retrieved: 3 documents\n",
      "   - Average doc length: 371 chars\n",
      "\n",
      "Test 3: Embeddings\n",
      "‚úÖ Embeddings operational\n",
      "   - Embedding dimensions: 384\n",
      "   - Model: sentence-transformers/all-MiniLM-L6-v2\n",
      "   - Rate limits: UNLIMITED (local)\n",
      "\n",
      "Test 4: Language Model\n",
      "‚úÖ LLM operational\n",
      "   - Model: groq\n",
      "   - Test response: Hello.\n",
      "\n",
      "Test 5: Translation Chain\n",
      "‚úÖ Translation chain operational\n",
      "   - Sample response: You're looking for the word \"test\". Let me check the dictionary for you.\n",
      "\n",
      "Accord...\n",
      "\n",
      "============================================================\n",
      "üìä SYSTEM STATUS\n",
      "============================================================\n",
      "‚úÖ Vector Database: 9,622 entries indexed\n",
      "‚úÖ Embeddings: Local (unlimited usage)\n",
      "‚úÖ LLM: groq (API-based)\n",
      "‚úÖ Total chunks: 9,622\n",
      "============================================================\n",
      "üéâ All systems operational! Ready to translate! üáµüá≠\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 12: Complete system test and diagnostics\n",
    "\n",
    "print(\"üß™ Running complete system diagnostics...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Check vectorstore\n",
    "print(\"Test 1: Vector Database\")\n",
    "try:\n",
    "    test_results = vectorstore.similarity_search(\"test\", k=1)\n",
    "    print(f\"‚úÖ Vector database operational\")\n",
    "    print(f\"   - Total vectors: {vectorstore.index.ntotal}\")\n",
    "    print(f\"   - Test query returned: {len(test_results)} results\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Vector database error: {e}\")\n",
    "\n",
    "# Test 2: Check retriever\n",
    "print(\"\\nTest 2: Retriever\")\n",
    "try:\n",
    "    test_retrieval = retriever.invoke(\"hello\")\n",
    "    print(f\"‚úÖ Retriever operational\")\n",
    "    print(f\"   - Retrieved: {len(test_retrieval)} documents\")\n",
    "    print(f\"   - Average doc length: {sum(len(d.page_content) for d in test_retrieval) // len(test_retrieval)} chars\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Retriever error: {e}\")\n",
    "\n",
    "# Test 3: Check embeddings\n",
    "print(\"\\nTest 3: Embeddings\")\n",
    "try:\n",
    "    test_embedding = embeddings.embed_query(\"test\")\n",
    "    print(f\"‚úÖ Embeddings operational\")\n",
    "    print(f\"   - Embedding dimensions: {len(test_embedding)}\")\n",
    "    print(f\"   - Model: sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    print(f\"   - Rate limits: UNLIMITED (local)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Embeddings error: {e}\")\n",
    "\n",
    "# Test 4: Check LLM\n",
    "print(\"\\nTest 4: Language Model\")\n",
    "try:\n",
    "    test_response = llm.invoke(\"Say hello in one word\")\n",
    "    print(f\"‚úÖ LLM operational\")\n",
    "    print(f\"   - Model: {MODEL_CHOICE}\")\n",
    "    print(f\"   - Test response: {test_response.content[:50]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM error: {e}\")\n",
    "\n",
    "# Test 5: Check full translation chain\n",
    "print(\"\\nTest 5: Translation Chain\")\n",
    "try:\n",
    "    test_translation = translator_chain.invoke(\"What does test mean?\")\n",
    "    print(f\"‚úÖ Translation chain operational\")\n",
    "    print(f\"   - Sample response: {test_translation[:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Translation chain error: {e}\")\n",
    "\n",
    "# System summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä SYSTEM STATUS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Vector Database: {vectorstore.index.ntotal:,} entries indexed\")\n",
    "print(f\"‚úÖ Embeddings: Local (unlimited usage)\")\n",
    "print(f\"‚úÖ LLM: {MODEL_CHOICE} (API-based)\")\n",
    "print(f\"‚úÖ Total chunks: {len(chunks):,}\")\n",
    "print(\"=\"*60)\n",
    "print(\"üéâ All systems operational! Ready to translate! üáµüá≠\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
